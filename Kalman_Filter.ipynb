{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Basic Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an attempt to motivate the Kalman filter in what I hope is a more intuitive way than many presentations.  Plus, I'll add several worked examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A brief outline\n",
    "This workbook (will) go through several problems for a variety of reasons.\n",
    "* Ready\n",
    "  * Simple 1-d problem.  Show that for a system with no dynamics and trivial measurement model the equantions are actually quite simple and reduce to what we would actually guess \n",
    "  * Code for Kalman Filter. \n",
    "  * Code for Steady State Values.  \n",
    "  \n",
    "* To Do\n",
    "  * Refer to the ambigious both optimal situation and show that it leads to a singularity\n",
    "  * Simple 2-d problem.  Show how Kalman filter handles filtering in the case with states\n",
    "  * Show how a straight filter can be better with no input\n",
    "  * Show impact of modeling error\n",
    "  * Show impact of non-gaussian error (uniform perhaps and bias)\n",
    "\n",
    "#### Version Info\n",
    "* Version 1.03\n",
    "* Status content: review through Kalman filter code and simple example\n",
    "* Status performance: generalized the Kalman filter code so it works symbolically or numerically\n",
    "* Notes: 1.03 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will start with a simple 1-d problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by estimating the acceleration of a simple 1d system.  For this reason we aren't worrying about constants or units, for this problem everything is \"unity.\"\n",
    "\n",
    "This has a real simple physical model\n",
    "* $a_k = u_k$ \n",
    "\n",
    "with\n",
    "\n",
    "* $a_k$ = acceleration at time k (the actual acceleration)\n",
    "* $u_k$ = is the input at time k\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We make the model  more realistic by allowing modeling error, often called process noise.  Calling it noise is an estimation and detection based way to think of it.  In that world view there are \"know\" or \"modeled\" quantities and \"unknown\" or \"noise.\" If you come to this from a more engineering based approach calling it noise may seem weird, after all it is modelign error however, either option works.\n",
    "\n",
    "\n",
    "* $a_k = u_k + q_k$\n",
    "\n",
    "with\n",
    "\n",
    "* $q_k$ = zero mean random variable representing process noise (modeling error) with covariance $Q$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The measurement model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with a trivial observation model, we add m to the subscript to indicate it is a measured quantity\n",
    "* $a_{mk} = a_k + r_k$\n",
    "\n",
    "with\n",
    "\n",
    "* $r_k$ = zero mean random variable representing observatioin noise (measurement error) with covaraince $R$ \n",
    "\n",
    "\n",
    "Pretty much anyone would call this noise, it is simply how off your sensor is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Acceleration a Naive Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need one little bit of additional notation.  It is pretty common in the estimation and detection literature to use $\\hat *$ to indicate an estimate.  In our case \n",
    "\n",
    "* $\\hat a_k$ is our estimation of accleration at time k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Most Basic Problem Estimate Acceleration In The No Noise No Modeling Error Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we could now estimate accleration with either of two equations \n",
    "* $a_{mk} = a_k + r_k$\n",
    "* $a_k = u_k + q_k$\n",
    "\n",
    "In the case of no measurement error $r_k=0$ and $q_k=0$ and no modeling errors these reduce to\n",
    "* $a_{mk} = a_k$\n",
    "* $a_k = u_k$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be clear that we now have the mathematically awkward, but practically ideal situation where have two optimal estimates.  Also note they are clearly optimal under any metric, since the estimate is always EXACTLY correct\n",
    "* $\\hat a_k =  a_{mk}$\n",
    "* $\\hat a_k =  u_{k}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only measurement or modeling error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have only measurement error $r_k$ but still no modeling error $q_k=0$ it should be clear that we now do have a best choice, and thus a single optimal choice\n",
    "\n",
    "* $\\hat a_k = u_k$\n",
    "\n",
    "Conversely if we have only modeling $q_k$ error and no measurement error $r_k$ we also have a single optimal choice\n",
    "\n",
    "* $\\hat a_k = a_{mk}$\n",
    "\n",
    "Again these are still clearly optimal under any metric as they are exactly the same as the quantity we are estimating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measurement and modeling error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if systems with no measurement error and no modeling error were common engineering and experimental physics would both be trivial. Clearly, for real systems we should expect both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $a_{mk} = a_k + r_k$\n",
    "* $a_k = u_k + q_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this case we want to ask what is the optimal estimate, seems like it should be some combination of the two estimates weighted by their relative noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most obvious model to propose is \n",
    "* $\\hat a_k = \\frac{q}{q+r} a_{mk} + \\frac{r}{q+r} u_k$\n",
    "\n",
    "With \n",
    "* no observation noise r = 0 this becomes $u_k$ \n",
    "* no modeling error q = 0 this becomes $a_{mk}$ \n",
    "* r = q this becomes $\\frac{1}{2} a_{mk} + \\frac{1}{2} u_k$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Acceleration With The Kalman Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's grind through the math of the Kalman filter and see what we get we will follow the version on Wiki\n",
    "https://en.wikipedia.org/wiki/Kalman_filter\n",
    "\n",
    "From Wiki, note this is matrix notation for now we won't worry about that and will just reduce everything to scalars \n",
    "We refer to the general form as Kalman and the equantions reduced to match our system as specalized.  We will follow the convention of vectors and matricies being capital letters.\n",
    "\n",
    "There is one exception that we will take a momentary detour for.  If you don't like matricies you can ignore this and all references to spaces below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measurement and state space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let't take our example but assume we have modeled both acceleration and velocity, now rather than a scalar our states are a vector\n",
    "\n",
    "* $X_k = \\left[ \\begin{matrix} a_k \\\\ v_k \\end{matrix} \\right]$\n",
    "\n",
    "We will introduce $Z$ for our measurement ($_m$) isn't a great notation for non-scalar quantities. \n",
    "Just to be difficult let's say our first sensor measures acceleration + velocity  and our second sensor measures acceleration\n",
    "\n",
    "* $Z_k = \\left[ \\begin{matrix} a_k + v_k \\\\ a_k \\end{matrix} \\right]$\n",
    "\n",
    "Expressed with the state vector\n",
    "\n",
    "* $Z_k = \\left[ \\begin{matrix} 1 & 1 \\\\ 1 & 0 \\end{matrix} \\right] * X_k$\n",
    "\n",
    "The matrix that multiplies $X$ is often called $H$ or $C$.  It should be clear that we have two state spaces here\n",
    "* $X_k$ and $Z_k$ which are related by the linear transform $H$\n",
    "* $Z_k = H X_k$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall our system model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $a_k = u_k + q_k$\n",
    "* $a_{mk} = a_k + r_k$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating notation to Kalman Filter Notation (from Wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kalman filter equation for the dynamics is \n",
    "* $X_k = F_k X_{k-1} + B_k U_k + W_k$\n",
    "\n",
    "\n",
    "* $W_k=\\mathcal{N}(0,\\,Q)$\n",
    "\n",
    "Some sources will use $A$ rather than $F$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referring back to our system model\n",
    "* $F_k = 0 $ this means there are no dynamics the state is instantaneously equal to the input\n",
    "* $B_k = 1 $ the state is equal to the input\n",
    "* $W_k = q_k$ scalar normal random variable with zero mean and variance q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kalman filter Wiki Notation for Measurement Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kalman filter equation for the measurement model is \n",
    "* $Z_k = H_k X_k + V_k$\n",
    "* $V_k=\\mathcal{N}(0,\\,R)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referring back to our system model\n",
    "* $H_k = 1 $ we observe the state itself (no scaling)\n",
    "* $V_k = r_k$ scalar normal random varianble with zero mean and variance r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman Filter\n",
    "In this section we use \"specalized\" to refer to the Kalman filter applied to our exact problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One more quick bit of notation\n",
    "The Kalman filter has a lot of terms that are similar.  You can distiguish them by using different variable names, but this becomes a LOT of variable names to keep track of (mentally). Instead usually what is used is conditioned subscripting, which follows the noation of conditional probabilities.\n",
    "\n",
    "For example\n",
    "*$X(k)_{k|k-1}$\n",
    "is read as $X_k$ given all the data to $k-1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kalman Predicted (a priori) state estimate\n",
    "You can think of this as the best guess of what the state will be based on knowledge of the input $u$ and our system model $F$ and $B$. This is a priori relative to the measurment.  It is the model of the system we have.\n",
    "If you are happy with spaces we note this is the state space, which in our simple problem is also the observation space:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kalman $\\hat X(k)_{k|k-1} = F_k \\hat X(k)_{k-1|k-1} + B_Ku_k$\n",
    "* Specalized $\\hat x(k)_{k|k-1} = u_k$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kalman Predicted (a priori) estimate of covariance\n",
    "You can think of this as the best guess of what the new covariance will be, again just using our system model.  Again we note we are still in the state space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kalman $P_{k|k−1}=F_kP_{k|k−1}F^T_k+Q_k$\n",
    "* Specalized $p_{k|k−1}=q_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kalman Innovation or measurement pre-fit residual\n",
    "This is where we measure how close our prediction is to the actual measurement, where $H_k$ tells us how the states map to the measurements.  Here we are in the measurement space.\n",
    "\n",
    "Note not all forms of the Kalman filter will define this term.  For example probabilistic robotics doesn't bother with this term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kalman    $\\tilde Y_k = Z_k - H_k \\hat X_{k|k-1}$\n",
    "* Specalized $\\tilde y_k = z_k -\\hat x_{k|k-1} = z_k - u_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kalman Post Fit Covariance\n",
    "This is our covariance updated based on the measurement. You can think of this as the total covariance.  Alternatively as as our modeled error (a priori) plus  error translated through the $H_k$ plus the measurement error in the measurement space $R_k$\n",
    "\n",
    "We are in the measurement space, this is clear by the fact that we are adding $R_k$\n",
    "* Kalman $S_k=H_kP_{k|k−1}H^T_k+R_k$\n",
    "* Specalized $S_k=P_{k|k−1}+R_k =q_k+r_k$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kalman Optimal Kalman Gain\n",
    "This can then be thought of as two terms $P_k$ our modeling error and $S_k$ our total error including measurement error with $H^T$ mapping this back to the state space\n",
    "\n",
    "Now we want to end up back in State space here so that is why we have $H^T_k$ before $S$ to translate S back to state space\n",
    "* Kalman $K_k = P_{k|k-1} H^T_k S^{-1}_k$\n",
    "* Noting that $H$ = 1 as derived in the system equivalent\n",
    "* Specalized $K_k = P_{k|k-1}  S^{-1}_k = q_k  (q_k + r_k)^{-1}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kalman Optimal Estimate of State\n",
    "* Updated (a posteriori) state estimate\n",
    "* Kalman $x_{k|k} = \\hat x_{k|k} + K_k* \\tilde y_k$\n",
    "* Specalized $x_{k|k} = u_k + \\frac{q_k}{q_k + r_k} * (z_k - u_k)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So an obvious quesiton is is this the same as our intuitive model?\n",
    "* Kalman Specalized $x_{k|k} = u_k + \\frac{Q_k}{Q_k + R_k} * (z_k - u_k)$\n",
    "* Intuitive $\\hat a_k = \\frac{q}{q+r} a_{mk} + \\frac{r}{q+r} u_k$\n",
    "\n",
    "If we simply add and subtract $\\frac{q}{q+r}u$ we get\n",
    "* $\\hat a_k = \\frac{q}{q+r} a_{mk} + \\frac{r}{q+r} u_k + \\frac{q}{q+r}u - \\frac{q}{q+r}u$\n",
    "* $=\\frac{q}{q+r} a_{mk} - \\frac{q}{q+r}u + \\frac{r}{q+r} u_k + \\frac{q}{q+r}u $\n",
    "* $=\\frac{q}{q+r} (a_{mk} - u) + u_k  $\n",
    "\n",
    "So as one might expect they are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may seem like an unsatisfying answer, since we had a ton of mathematical structure in the Kalman filter and it all came down to a simple solution.  This however is the wrong way to think about it.  Instead, it's great that our intuition matches the Kalman filter and we have an idea about what each term does.  \n",
    "\n",
    "Further, if we look at simplicication $H$ being identity is not too bad.   While we often don't get to measure all the states it isn't a crazy assumption. It is just how complexly the measurement space is related to the state space.  \n",
    "\n",
    "However, we should note that $F$ being zero is a pretty sever assumption and a non-zero $F$ is what we will look at next.  \n",
    "\n",
    "It is also interesting to think about different optimality criterion.  Let's assume that bosth the measurement and process noise are high, but the known input $u$ is always zero.  The Kalman filter will still be the optimal instantenious estimate of the state however, if we want the best steady state value it's clear that we rather have an additional filter on the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's up with all the \"optimal\" stuff\n",
    "\n",
    "The Kalman Filter is the optimal linear estimator of the mean squared error of the states given known covariances.  It is useful to know it is optimal because for the stated conditions you know you don't need to look for another better algorithm.  It is also useful to notice which of these are \"stronng\" assumptions.  \n",
    "\n",
    "* The most restrictive assumption is that the initial system is linear.  The extended Kalman filter reduces that restriction at the cost not just of optimality but even covergence, except under certain limiting cases.  This makes sense, you extend the class of problems handled but not to everything.\n",
    "\n",
    "* The next strongest is reducing the problem to linear estimators.  We can think of all algorithms as being part of the class of non-linear estimators.  Withing this class there is a small class of linear estimators.  The primary limitation of linear estimators is the inability to discard completely bogus data.  To do so you need some type of nonlinearity.\n",
    "\n",
    "* Finally we bring in that it is an estimator.  This means that you can't have future knowledge impact previous states.  You can argue that this is one of the primary reasons that graph based algorithms for SLAM surplanted Kalman filter algorithms, the ability to update past values with future data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Functional Kalman Filter\n",
    "The above discussion should be motivational, but the Kalman filter is itterative so it would be far better to have it written as a function rather than cells.\n",
    "\n",
    "We will actually define it so it can be used symbolically or numerically.  We will make use of the symbolic functionality to make sure we have coded it to match what we have above.\n",
    "\n",
    "I don't think it is particularly important to follow through the code, though if you are looking for examples of how to do this in Python it could be handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regeneralizing for symbolic\n",
    "import numpy as np\n",
    "import sympy as sym\n",
    "import random\n",
    "from scipy import linalg\n",
    "\n",
    "#Utility fcn\n",
    "def print_matrix(lcl_header_str, lcl_matrix):\n",
    "    if (isinstance(lcl_matrix, sym.Matrix)):\n",
    "        lcl_outmtrx = str(lcl_matrix)\n",
    "    else:\n",
    "        lcl_matrix =  np.matrix(lcl_matrix).astype(np.float64)\n",
    "    lcl_blanks = \" \"*len(lcl_header_str)\n",
    "    lcl_outmtrx = lcl_outmtrx.replace('\\n','\\n'+lcl_blanks)\n",
    "    #outmtrx.replace('\\n','\\n'+blanks)\n",
    "    print(lcl_header_str, lcl_outmtrx)\n",
    "\n",
    "#Also repeat some definitions to make things more free standing\n",
    "gDef_Noise = 0.01\n",
    "\n",
    "#Since workbooks invite global variables we will use pedantic in function naming convention of lcl_ for local variables to avoid any\n",
    "#accidental collision with globals\n",
    "\n",
    "class Dynamic_System:\n",
    "    #For now no looping in this level\n",
    "    def __init__(self, lcl_X_init, lcl_A, lcl_B, lcl_R, lcl_C, lcl_Q, lcl_verbose=0):\n",
    "        #Copy over verbose\n",
    "        self.verbose = lcl_verbose\n",
    "        #Initial state\n",
    "        self.X = lcl_X_init\n",
    "        if self.verbose>3:\n",
    "            print(\"Initial X\", self.X)\n",
    "        #State transition\n",
    "        self.A = lcl_A\n",
    "        #Inputs\n",
    "        self.B = lcl_B\n",
    "        #Noise on dynamics\n",
    "        self.R = lcl_R\n",
    "        #Observation model\n",
    "        self.C = lcl_C\n",
    "        #Noise on observation\n",
    "        self.Q = lcl_Q\n",
    "        #Make random numbers repeatible\n",
    "        self.flatten = sym.Matrix.ones(self.Q.shape[0],1)\n",
    "        random.seed(0)\n",
    "    def calc_cov(self, lcl_Cov):\n",
    "        #In terms of std not variance\n",
    "        #return (random.gauss(0*lcl_Cov,lcl_Cov*lcl_Cov)*self.flatten)\n",
    "        lcl_Std = lcl_Cov**(1/2)\n",
    "        #Somewhat surprisingly trying this a duck typing doesn't work the random.gauss just get's magically appended\n",
    "        if (isinstance(lcl_Std, sym.Matrix)):\n",
    "            return (lcl_Std)\n",
    "        else:\n",
    "            return (random.gauss(0*lcl_Std,lcl_Std)*self.flatten)\n",
    "        \n",
    "    def get_model(self):\n",
    "        return(self.A, self.B, self.R, self.C, self.Q)\n",
    "    def get_dynamics(self):\n",
    "        return(self.A, self.B, self.C)\n",
    "    def dynamics(self, lcl_input, lcl_X):\n",
    "        lcl_dyn_upt = self.A * lcl_X + self.B * lcl_input\n",
    "        if self.verbose>=2:\n",
    "            print(\"Dynamics Update\")\n",
    "            print(lcl_dyn_upt)\n",
    "        return(lcl_dyn_upt)\n",
    "    def update(self, lcl_input):\n",
    "        #Evolve state\n",
    "        #for current_input in input:\n",
    "        #    print (\"Current Input \")\n",
    "        #    print (current_input)\n",
    "        #    print(current_input.shape)\n",
    "\n",
    "        lcl_dyn_err = self.calc_cov(self.R)\n",
    "            \n",
    "        if self.verbose>3:\n",
    "            print(\" DYNAMICS_UPDATE\")\n",
    "            print(\"Model Error \", self.R)\n",
    "            print(\"Dynamics Error\", lcl_dyn_err)\n",
    "            print(\"input\", lcl_input)\n",
    "            print(\"state before update\", self.X)\n",
    "\n",
    "        self.X = self.dynamics(lcl_input, self.X + lcl_dyn_err)\n",
    "\n",
    "        if self.verbose>3:\n",
    "            print(\"state after update\", self.X)\n",
    "\n",
    "            \n",
    "            \n",
    "    def show(self):\n",
    "        print (\"Initial state\")\n",
    "        print (self.X)\n",
    "        print (\"A -- dynamics\")\n",
    "        print (self.A)\n",
    "        print (\"B -- impact of input\")\n",
    "        print (self.B)\n",
    "        print (\"R -- assumed dynamic errors\")\n",
    "        print (self.R)\n",
    "        print (\"C -- state observation model\")\n",
    "        print (self.C)\n",
    "        print (\"Q -- noise on state observation\")\n",
    "        print (self.Q)\n",
    "    def state(self):\n",
    "        #Return state, useful primarly for debugging\n",
    "        return(self.X)\n",
    "    def observe(self):\n",
    "        #Return observation, should generally be used rather than state\n",
    "        #return(self.C*self.X+self.calc_cov(self.Q)*self.flatten)\n",
    "        if self.verbose>3:\n",
    "            print(\"C\", self.C)\n",
    "            print(\"X\", self.X)\n",
    "            print(\"Q\", self.Q)\n",
    "            print(\"Cov\")\n",
    "            print(self.calc_cov(self.Q))\n",
    "        return(self.C*self.X+self.calc_cov(self.Q))\n",
    "\n",
    "class Kalman_Filter:\n",
    "    #Loops are done here\n",
    "    def __init__(self, lcl_Dynamic_System, lcl_Sigma_Init, lcl_X_init, lcl_R, lcl_Q, lcl_verbose=0):\n",
    "        self.verbose = lcl_verbose\n",
    "        self.Dynamic_System = lcl_Dynamic_System\n",
    "        self.Sigma = lcl_Sigma_Init\n",
    "        self.X = lcl_X_init\n",
    "        self.R = lcl_R\n",
    "        self.Q = lcl_Q\n",
    "        if self.verbose>3:\n",
    "            print(\"Dynamic System\")\n",
    "            self.Dynamic_System.show()\n",
    "            print(\"Kalman System\")\n",
    "            print (\"  Initial State Kalman Filter \", self.X)\n",
    "            print (\"  R\", self.R)\n",
    "            print (\"  Q\", self.Q)\n",
    "\n",
    "        \n",
    "    def update(self, lcl_input):\n",
    "\n",
    "        #Extract required info from dynamic system\n",
    "        lcl_A, lcl_B, lcl_C= self.Dynamic_System.get_dynamics()\n",
    "        \n",
    "        #Create empty vectors\n",
    "        self.X_act_hist = [self.Dynamic_System.state()]\n",
    "        self.X_filt_hist = [self.X]\n",
    "        self.K_hist = [self.Sigma]\n",
    "\n",
    "        for lcl_current_input in lcl_input:\n",
    "            if self.verbose>2:\n",
    "                print(\"\")\n",
    "                print(\"KALMAN FILTER CALCULATION\")\n",
    "                print(\"\")\n",
    "                print(\"  Current Input\", lcl_current_input)\n",
    "            #Evolve the actual state\n",
    "            self.Dynamic_System.update(lcl_current_input)\n",
    "\n",
    "            #Calculate Kalman filter following https://en.wikipedia.org/wiki/Kalman_filter\n",
    "\n",
    "            \n",
    "            ##Predict\n",
    "            ###Compute Predicted X  (predicted a priori state estimte)\n",
    "            lcl_X_pred = self.Dynamic_System.dynamics(lcl_current_input, self.X)\n",
    "            if self.verbose>2:\n",
    "                print(\"\")\n",
    "                print (\"  Predicted X\", lcl_X_pred)\n",
    "            ####First step in covariance calculation based on dynamics and dynamics \"noise\"\n",
    "            if self.verbose>3:\n",
    "                print (\"Sigma\")\n",
    "                print (self.Sigma)\n",
    "\n",
    "            ###Compute Predicted P covariance\n",
    "            lcl_Sigma_Step_1 = lcl_A*self.Sigma*lcl_A.T+self.Q\n",
    "            if self.verbose>2:\n",
    "                print (\"  Predicted Covariance\", lcl_Sigma_Step_1)\n",
    "            \n",
    "\n",
    "            #Observe the system\n",
    "            lcl_Z = self.Dynamic_System.observe()\n",
    "            if self.verbose>3:\n",
    "                print (\"    Observed Value\")\n",
    "                print (lcl_Z)\n",
    "            \n",
    "            \n",
    "            ##Update\n",
    "\n",
    "            ###Calculate innovation pre-fit residual (error)\n",
    "            lcl_Y = lcl_Z - lcl_C * lcl_X_pred\n",
    "\n",
    "            ###Calculate innovation (or pre-fit redidual) covariance\n",
    "            #self.Sigma = (sym.Matrix.eye(2)-lcl_K*lcl_C)*lcl_Sigma_Step_1\n",
    "            self.Sigma = lcl_C * lcl_Sigma_Step_1 * lcl_C.T + self.R\n",
    "            if self.verbose>2:\n",
    "                print(\"  Innovation Covariance \", self.Sigma)\n",
    "            \n",
    "            #Compute the Kalman gain (used to weight observations and measurements)\n",
    "            #lcl_K = lcl_Sigma_Step_1 * lcl_C.T * (lcl_C*lcl_Sigma_Step_1*lcl_C.T + self.Q).inv()\n",
    "            lcl_K = lcl_Sigma_Step_1 * lcl_C.T * self.Sigma.inv()\n",
    "            if self.verbose>2:\n",
    "                print (\"  Updated Kalman Gain\", lcl_K)\n",
    "                \n",
    "            ###Updated (a posteriori) state estimate\n",
    "            lcl_X_filt = lcl_X_pred + lcl_K * (lcl_Y)\n",
    "            self.X = lcl_X_filt\n",
    "            \n",
    "            ###Updated (a posterriori) estimate of covariance\n",
    "            ###Get size of matrix\n",
    "            lcl_temp = lcl_K*lcl_C\n",
    "            ###Possible error, have to check if this must be square\n",
    "            lcl_size = lcl_temp.shape[1]\n",
    "            self.Sigma = (sym.Matrix.eye(lcl_size)-lcl_K*lcl_C)*lcl_Sigma_Step_1\n",
    "            if self.verbose>2:\n",
    "                print (\"  Updated (a posteriori) estimate of covariance\", self.Sigma)\n",
    "            \n",
    "            #Store relevant information in a vector\n",
    "            self.X_act_hist.append(self.Dynamic_System.state())\n",
    "            self.X_filt_hist.append(lcl_X_filt)\n",
    "            self.K_hist.append(lcl_K)\n",
    "            \n",
    "        if self.verbose>=1:\n",
    "            print(\"Final Values\")\n",
    "            print_matrix(\" X                          \", self.Dynamic_System.state())\n",
    "            print_matrix(\" Kalman Estimate of State X \", lcl_X_filt)\n",
    "            print_matrix(\" Final Covariance S(igma)   \", self.Sigma)\n",
    "            print_matrix(\" Final Kalman Gains K       \", lcl_K)\n",
    "    #def show(self):\n",
    "        #for idx in range(length(self.X_act_hist)):\n",
    "        #    print(\"State\")\n",
    "        #    print(self.X_act_hist.append[idx])\n",
    "        #    print(\"Kalman Estimate\")\n",
    "        #    print(self.X_filt_hist[idx])\n",
    "        #    print(\"Kalman Gain\")\n",
    "        #    print(self.K_hist[idx])\n",
    "\n",
    "def asymptotic_kal(lcl_A=[], lcl_B=[], lcl_R=[], lcl_C=[], lcl_Q=[], lcl_verbose=0):\n",
    "    lcl_An = np.matrix(lcl_A).astype(np.float64)\n",
    "    lcl_Bn = np.matrix(lcl_B).astype(np.float64)\n",
    "    lcl_Cn = np.matrix(lcl_C).astype(np.float64)\n",
    "    lcl_Qn = np.matrix(lcl_Q).astype(np.float64)\n",
    "    lcl_Rn = np.matrix(lcl_R).astype(np.float64)\n",
    "    \n",
    "    lcl_gP = linalg.solve_discrete_are(lcl_An, lcl_Cn, lcl_Qn, lcl_Rn)\n",
    "    #Change of notation\n",
    "    #gFn1 = gA1\n",
    "    #gGn1 = gB1\n",
    "    #gHn1 = gC1\n",
    "    #gRn1 = gR11\n",
    "    lcl_K = lcl_gP*lcl_Cn.T*((lcl_Cn*lcl_gP*lcl_Cn.T + lcl_Rn).I)\n",
    "    lcl_S = lcl_gP-lcl_K*lcl_Cn*lcl_gP\n",
    "    lcl_P = lcl_An*lcl_S*lcl_An.T + lcl_Bn*lcl_Qn*lcl_Bn.T\n",
    "    if lcl_verbose>0:\n",
    "        print(\"Asymptotic Evaluation of: \")\n",
    "        print_matrix(\" Covariance Matrix S(igma) \", lcl_S)\n",
    "        print_matrix(\" Kalman Gain K             \", lcl_K)\n",
    "    return(lcl_S, lcl_K, lcl_P)\n",
    "        \n",
    "#Define a utility function to setup up consistent dynamics and Kalman Filter\n",
    "def matched_system(lcl_A=[], lcl_B=[], lcl_X=[], lcl_R=[], lcl_C=[], lcl_Q=[],  lcl_Sigma=[], lcl_verbose=0):\n",
    "    #We note that the noise for our dynamic system is defined in terms for std not var\n",
    "    lcl_R2 = np.matrix(lcl_R).astype(np.float64)\n",
    "    #look into\n",
    "    #lcl_R2 = linalg.sqrtm(lcl_R2)\n",
    "    lcl_Q2 = np.matrix(lcl_Q).astype(np.float64)\n",
    "    #lcl_Q2 = linalg.sqrtm(lcl_Q2)\n",
    "    \n",
    "    lcl_dyn_sys = Dynamic_System(lcl_X, lcl_A, lcl_B, lcl_R2, lcl_C, lcl_Q2, lcl_verbose=lcl_verbose)\n",
    "    lcl_kal = Kalman_Filter(lcl_dyn_sys, lcl_Sigma, lcl_X, lcl_R, lcl_Q, lcl_verbose=lcl_verbose)\n",
    "    asymptotic_kal(lcl_A, lcl_B, lcl_R, lcl_C, lcl_Q,  lcl_verbose)\n",
    "    return(lcl_kal)\n",
    "\n",
    "\n",
    "def repeat_input(input, times):\n",
    "    input_list = [input]\n",
    "    for idx in range(times-1):\n",
    "        input_list.append(input)\n",
    "    return(input_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use this on our simple system\n",
    "\n",
    "We set verbose to 0 for the dynamic system, we don't want to see any of it's calculations\n",
    "We set verbose to 3 for the kalman filter, we do want to see it's intermediate calculations\n",
    "\n",
    "Also since this is done for us we relax the assumption on zero initial state and covariance matrix we used above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KALMAN FILTER CALCULATION\n",
      "\n",
      "  Current Input Matrix([[u]])\n",
      "\n",
      "  Predicted X Matrix([[u + xi]])\n",
      "  Predicted Covariance Matrix([[q**2 + si]])\n",
      "  Innovation Covariance  Matrix([[q**2 + r**2 + si]])\n",
      "  Updated Kalman Gain Matrix([[(q**2 + si)/(q**2 + r**2 + si)]])\n",
      "  Updated (a posteriori) estimate of covariance Matrix([[(q**2 + si)*(-(q**2 + si)/(q**2 + r**2 + si) + 1)]])\n",
      "Final Values\n",
      " X                           Matrix([[u + xi + (r**2)**0.5]])\n",
      " Kalman Estimate of State X  Matrix([[u + xi + (q**2 + si)*((q**2)**0.5 + (r**2)**0.5)/(q**2 + r**2 + si)]])\n",
      " Final Covariance S(igma)    Matrix([[(q**2 + si)*(-(q**2 + si)/(q**2 + r**2 + si) + 1)]])\n",
      " Final Kalman Gains K        Matrix([[(q**2 + si)/(q**2 + r**2 + si)]])\n"
     ]
    }
   ],
   "source": [
    "#Initial state\n",
    "gx_init =  sym.symbols('xi')\n",
    "gX_init  = sym.Matrix([[gx_init]])\n",
    "#Dynamics\n",
    "gA = sym.Matrix([[1]])\n",
    "#Inputs\n",
    "gB = sym.Matrix([[1]])\n",
    "#Mapping of states to measurements\n",
    "gC = sym.Matrix([[1]])\n",
    "#Noise on dynamics\n",
    "gr =  sym.symbols('r')\n",
    "gR = sym.Matrix([[gr**2]])\n",
    "#Noise on measurements\n",
    "gq =  sym.symbols('q')\n",
    "gQ = sym.Matrix([[gq**2]])\n",
    "gDyn_sys = Dynamic_System(gX_init, gA, gB, gR, gC, gQ, lcl_verbose=0)\n",
    "#Create a single input\n",
    "gu = sym.symbols('u')\n",
    "gsingle_input = repeat_input(sym.Matrix([[gu]]),1)\n",
    "#Initial covariance matrix\n",
    "gsigma_init = sym.symbols('si')\n",
    "gSigma_Init =  sym.Matrix([[gsigma_init]])\n",
    "#Call the raw calman filter\n",
    "gKal = Kalman_Filter(gDyn_sys, gSigma_Init, gX_init, gR, gQ, lcl_verbose=3)\n",
    "\n",
    "#gKal = matched_system(lcl_A=gA, lcl_B=gB, lcl_X=gX_init, lcl_R=gR, lcl_C=gC, lcl_Q=gQ, lcl_Sigma=gSigma_Init, lcl_verbose=1)\n",
    "gKal.update(gsingle_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as expected the calcualted Kalman gain matches what we derived piece by piece.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Of Vetted Part of Sheet\n",
    "Note actually the Kalman filter code below works, but I haven't really thought of how I want to tie it all together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My next steps are\n",
    "1. Put in a simulation for the case mentioned above\n",
    "2. Work through an example with dynamics\n",
    "Note the rest of the sheet is somewhat unstructured.  Thought the code for a Kalman filter works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* Specalized $x_{k|k} = u_k + \\frac{Q_k}{Q_k + R_k} * (z_k - u_k)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* If we take R=0 then this reduces to \n",
    "* Specalized $x_{k|k} = u_k + 1 * (z_k - u_k) = z_k$\n",
    "* If we take R>0 and Q=0\n",
    "* Specalized $x_{k|k} = u_k + 1 * (z_k - u_k) = u_k$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step put in some modeling dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### A Basic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some general notes\n",
    "--The naming conventions in this worksheet are NOT recommended for general work.  Worksheets, particularly worksheets to be shared have the high risk of accidentally using a global variable when a local variable was intended.  This is particularly true because the generic namespace is the global name space.  I would NOT recommend following this convention in any conventional programming.\n",
    "--Obviously this is python and it's libraries, if you aren't familiar with them don't worry you can just ignore the programming steps and follow along with the description\n",
    "--The markdown uses Latex, if you are familiar great, if not I wouldn't worry too much about learning it.  Latex has a sort of steep entry curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the most basic system\n",
    "--Robot on a plane\n",
    "--Linear dynamics\n",
    "--No noise\n",
    "--Trivial coordinates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dynamics are \n",
    "Standard dynamics are:\n",
    "\n",
    "$ x_{k} = A_k x_{k-1} + B_ku_k + w_k$\n",
    "\n",
    "\n",
    "Note some other letters are $A, B = F, G$ and $w = r$\n",
    "\n",
    "\n",
    "\n",
    "We then observe the state with\n",
    "\n",
    "$ z_k = C_kx_k + v_k $\n",
    "\n",
    "\n",
    "Note some alternative letters for $H = C$ and $q = v$.  The \"hat\" notation is pretty standard for estimate.\n",
    "\n",
    "\n",
    "$\\hat x(k)_{k|k-1} = F_k \\hat x(k)_{k-1|k-1} + B_Ku_k$\n",
    "\n",
    "or\n",
    "\n",
    "$\\hat x(k)_{k|k-1} = A_k \\hat x(k)_{k-1|k-1} + B_Ku_k$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run into a classic problem we want to do symbolic math not numeric.  Maple or Mathematic would be a better place to do this but I think we will be able to get by in Python, let's find out.\n",
    "https://paulpotgieter.org/2020/10/30/solving-symbolic-matrix-equations-in-python-with-sympy/\n",
    "http://scipy-lectures.org/packages/sympy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sym\n",
    "import random\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model without noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are defining the simpliest discrete time model.  There are two independent states, two independent controls, and two independent observations.  In discrete time this drives a model that is mostly just identity matricies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Ax$\n",
    "\n",
    "Define the dynamics, how state evolves based on past state (the homogenious part of a differential equation)\n",
    "\n",
    "$A = \\begin{matrix} 1 & 0 \\\\ 0 & 1 \\end{matrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix([\n",
       "[x],\n",
       "[y]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gA = sym.Matrix([[1, 0], [0, 1]])\n",
    "gx, gy = sym.symbols('x, y')\n",
    "gX = sym.Matrix([[gx], [gy]])\n",
    "gA*gX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Bu$\n",
    "\n",
    "$B = \\begin{matrix} 1 & 0 \\\\ 0 & 1 \\end{matrix}$\n",
    "\n",
    "Define how the state evolves based on the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix([\n",
       "[ux],\n",
       "[uy]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gB = sym.Matrix([[1, 0], [0, 1]])\n",
    "gux, guy = sym.symbols('ux, uy')\n",
    "gU = sym.Matrix([[gux], [guy]])\n",
    "gB*gU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z_k = C_k x_k $\n",
    "\n",
    "$C = \\begin{matrix} 1 & 0 \\\\ 0 & 1 \\end{matrix}$\n",
    "\n",
    "Define the observation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix([\n",
       "[ux + x],\n",
       "[uy + y]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gC = sym.Matrix([[1, 0], [0, 1]])\n",
    "gC*(gA*gX+gB*gU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test this out, note this appears to print in alphabetic order which is kind of a bummer but oh well\n",
    "What this says is the the observation is exactly the state, not surprising in this trivial example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the R matrix, this is our assumed noise model for the dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix([\n",
       "[rx,  0],\n",
       "[ 0, ry]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grx, gry = sym.symbols('rx, ry')\n",
    "gR = sym.Matrix([[grx, 0], [0, gry]])\n",
    "gR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Q matrix, this is our assumed noise model for the measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix([\n",
       "[qx,  0],\n",
       "[ 0, qy]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gqx, gqy = sym.symbols('qx, qy')\n",
    "gQ = sym.Matrix([[gqx, 0], [0, gqy]])\n",
    "gQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the specific noise models\n",
    "--start with noise free\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix([\n",
       "[0, 0],\n",
       "[0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gQn = gQ.subs('qx', 0).subs('qy', 0)\n",
    "gRn = gR.subs('rx', 0).subs('ry', 0)\n",
    "gQn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE THE KALMAN FILTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Sigma Matrix, this keeps track of the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix([\n",
       "[sx,  0],\n",
       "[ 0, sy]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsx, gsy = sym.symbols('sx, sy')\n",
    "gSigma = sym.Matrix([[gsx, 0], [0, gsy]])\n",
    "gSigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial State Estimate\n",
    "\n",
    "$x = \\begin{matrix} 0 \\\\ 0 \\end{matrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gX = sym.Matrix([[0], [0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kalman Loop (note .T is transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Predicted X  (predicted a priori state estimte)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat x(k)_{k|k-1} = F_k \\hat x(k)_{k-1|k-1} + B_Ku_k$\n",
    "\n",
    "$\\hat x(k)_{k|k-1} = A_k \\hat x(k)_{k-1|k-1} + B_Ku_k$\n",
    "\n",
    "Note that the exact discrete time indicies may vary depending on formulation but it should take the form of current x is A* past x + B * current input\n",
    "\n",
    "As expected since our initial state was 0, 0 this is just the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix([\n",
       "[ux],\n",
       "[uy]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "   gX_pred = gA*gX + gB*gU\n",
    "   gX_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Predicted P covariance\n",
    "\n",
    "$P_{k|k-1} = F_k P_{k|k-1} F^T_k +Q_k$\n",
    "\n",
    "or\n",
    "\n",
    "$\\Sigma_{k|k-1} = A_k \\Sigma_{k|k-1} A^T_k +Q_k$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix([\n",
       "[rx + sx,       0],\n",
       "[      0, ry + sy]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  gSigma_Step_1s = gA*gSigma*gA.T+gR\n",
    "  gSigma_Step_1s\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Innovation or pre-fit residual\n",
    "\n",
    "$S_k = H_k P_{k|k-1} H^T_k + R_k$\n",
    "\n",
    "or \n",
    "\n",
    "$\\Sigma_{k} = C_k \\Sigma_{k|k-1} C^T_k + R_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix([\n",
       "[sx,  0],\n",
       "[ 0, sy]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  \n",
    "gSigma_Step_1n = gA*gSigma*gA.T+gRn\n",
    "gSigma_Step_1n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute The Kalman Gain\n",
    "\n",
    "$K_k = P_{k|k-1} H^T_k P^{-1}_k$\n",
    "\n",
    "$K_k = \\Sigma_{k|k-1} C^T_k \\Sigma^{-1}_k$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix([\n",
       "[(rx + sx)/(qx + rx + sx),                        0],\n",
       "[                       0, (ry + sy)/(qy + ry + sy)]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  gKs = gSigma_Step_1s * gC.T * (gC*gSigma_Step_1s*gC.T + gQ).inv()\n",
    "  gKs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Compute Kalman Gain, weighting between model and measurements for our specific case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix([\n",
       "[1, 0],\n",
       "[0, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  gKn = gSigma_Step_1n * gC.T * (gC*gSigma_Step_1n*gC.T + gQn).inv()\n",
    "  gKn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Actually in this case any Kalman gain is as good as any other one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Compute X based on the measurement, Kalman gain, and predection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Create an observation, based on our noise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix([\n",
       "[0],\n",
       "[0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  gZ = gC*gX+gQn*sym.Matrix([[1], [1]])\n",
    "  gZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Update the filtered value of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix([\n",
       "[0],\n",
       "[0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  gX_filt = gX_pred + gKn * (gZ - gC*gX_pred)\n",
    "  gX_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Update the value of the Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix([\n",
       "[0, 0],\n",
       "[0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  gSigma_Finaln = (sym.Matrix.eye(2)-gKn*gC)*gSigma_Step_1n\n",
    "  gSigma_Finaln\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note we now have a zero matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make this more computable we will define a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrix([\n",
       "[rx,  0],\n",
       "[ 0, ry]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some functions so we can do this itteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regeneralizing for symbolic\n",
    "import numpy as np\n",
    "import sympy as sym\n",
    "import random\n",
    "from scipy import linalg\n",
    "\n",
    "#Utility fcn\n",
    "def print_matrix(lcl_header_str, lcl_matrix):\n",
    "    if (isinstance(lcl_matrix, sym.Matrix)):\n",
    "        lcl_outmtrx = str(lcl_matrix)\n",
    "    else:\n",
    "        lcl_matrix =  np.matrix(lcl_matrix).astype(np.float64)\n",
    "    lcl_blanks = \" \"*len(lcl_header_str)\n",
    "    lcl_outmtrx = lcl_outmtrx.replace('\\n','\\n'+lcl_blanks)\n",
    "    #outmtrx.replace('\\n','\\n'+blanks)\n",
    "    print(lcl_header_str, lcl_outmtrx)\n",
    "\n",
    "#Also repeat some definitions to make things more free standing\n",
    "gDef_Noise = 0.01\n",
    "\n",
    "#Since workbooks invite global variables we will use pedantic in function naming convention of lcl_ for local variables to avoid any\n",
    "#accidental collision with globals\n",
    "\n",
    "class Dynamic_System:\n",
    "    #For now no looping in this level\n",
    "    def __init__(self, lcl_X_init, lcl_A, lcl_B, lcl_R, lcl_C, lcl_Q, lcl_verbose=0):\n",
    "        #Copy over verbose\n",
    "        self.verbose = lcl_verbose\n",
    "        #Initial state\n",
    "        self.X = lcl_X_init\n",
    "        if self.verbose>3:\n",
    "            print(\"Initial X\", self.X)\n",
    "        #State transition\n",
    "        self.A = lcl_A\n",
    "        #Inputs\n",
    "        self.B = lcl_B\n",
    "        #Noise on dynamics\n",
    "        self.R = lcl_R\n",
    "        #Observation model\n",
    "        self.C = lcl_C\n",
    "        #Noise on observation\n",
    "        self.Q = lcl_Q\n",
    "        #Make random numbers repeatible\n",
    "        self.flatten = sym.Matrix.ones(self.Q.shape[0],1)\n",
    "        random.seed(0)\n",
    "    def calc_cov(self, lcl_Cov):\n",
    "        #In terms of std not variance\n",
    "        #return (random.gauss(0*lcl_Cov,lcl_Cov*lcl_Cov)*self.flatten)\n",
    "        lcl_Std = lcl_Cov**(1/2)\n",
    "        #Somewhat surprisingly trying this a duck typing doesn't work the random.gauss just get's magically appended\n",
    "        if (isinstance(lcl_Std, sym.Matrix)):\n",
    "            return (lcl_Std)\n",
    "        else:\n",
    "            return (random.gauss(0*lcl_Std,lcl_Std)*self.flatten)\n",
    "        \n",
    "    def get_model(self):\n",
    "        return(self.A, self.B, self.R, self.C, self.Q)\n",
    "    def get_dynamics(self):\n",
    "        return(self.A, self.B, self.C)\n",
    "    def dynamics(self, lcl_input, lcl_X):\n",
    "        lcl_dyn_upt = self.A * lcl_X + self.B * lcl_input\n",
    "        if self.verbose>=2:\n",
    "            print(\"Dynamics Update\")\n",
    "            print(lcl_dyn_upt)\n",
    "        return(lcl_dyn_upt)\n",
    "    def update(self, lcl_input):\n",
    "        #Evolve state\n",
    "        #for current_input in input:\n",
    "        #    print (\"Current Input \")\n",
    "        #    print (current_input)\n",
    "        #    print(current_input.shape)\n",
    "\n",
    "        lcl_dyn_err = self.calc_cov(self.R)\n",
    "            \n",
    "        if self.verbose>3:\n",
    "            print(\" DYNAMICS_UPDATE\")\n",
    "            print(\"Model Error \", self.R)\n",
    "            print(\"Dynamics Error\", lcl_dyn_err)\n",
    "            print(\"input\", lcl_input)\n",
    "            print(\"state before update\", self.X)\n",
    "\n",
    "        self.X = self.dynamics(lcl_input, self.X + lcl_dyn_err)\n",
    "\n",
    "        if self.verbose>3:\n",
    "            print(\"state after update\", self.X)\n",
    "\n",
    "            \n",
    "            \n",
    "    def show(self):\n",
    "        print (\"Initial state\")\n",
    "        print (self.X)\n",
    "        print (\"A -- dynamics\")\n",
    "        print (self.A)\n",
    "        print (\"B -- impact of input\")\n",
    "        print (self.B)\n",
    "        print (\"R -- assumed dynamic errors\")\n",
    "        print (self.R)\n",
    "        print (\"C -- state observation model\")\n",
    "        print (self.C)\n",
    "        print (\"Q -- noise on state observation\")\n",
    "        print (self.Q)\n",
    "    def state(self):\n",
    "        #Return state, useful primarly for debugging\n",
    "        return(self.X)\n",
    "    def observe(self):\n",
    "        #Return observation, should generally be used rather than state\n",
    "        #return(self.C*self.X+self.calc_cov(self.Q)*self.flatten)\n",
    "        if self.verbose>3:\n",
    "            print(\"C\", self.C)\n",
    "            print(\"X\", self.X)\n",
    "            print(\"Q\", self.Q)\n",
    "            print(\"Cov\")\n",
    "            print(self.calc_cov(self.Q))\n",
    "        return(self.C*self.X+self.calc_cov(self.Q))\n",
    "\n",
    "class Kalman_Filter:\n",
    "    #Loops are done here\n",
    "    def __init__(self, lcl_Dynamic_System, lcl_Sigma_Init, lcl_X_init, lcl_R, lcl_Q, lcl_verbose=0):\n",
    "        self.verbose = lcl_verbose\n",
    "        self.Dynamic_System = lcl_Dynamic_System\n",
    "        self.Sigma = lcl_Sigma_Init\n",
    "        self.X = lcl_X_init\n",
    "        self.R = lcl_R\n",
    "        self.Q = lcl_Q\n",
    "        if self.verbose>3:\n",
    "            print(\"Dynamic System\")\n",
    "            self.Dynamic_System.show()\n",
    "            print(\"Kalman System\")\n",
    "            print (\"  Initial State Kalman Filter \", self.X)\n",
    "            print (\"  R\", self.R)\n",
    "            print (\"  Q\", self.Q)\n",
    "\n",
    "        \n",
    "    def update(self, lcl_input):\n",
    "\n",
    "        #Extract required info from dynamic system\n",
    "        lcl_A, lcl_B, lcl_C= self.Dynamic_System.get_dynamics()\n",
    "        \n",
    "        #Create empty vectors\n",
    "        self.X_act_hist = [self.Dynamic_System.state()]\n",
    "        self.X_filt_hist = [self.X]\n",
    "        self.K_hist = [self.Sigma]\n",
    "\n",
    "        for lcl_current_input in lcl_input:\n",
    "            if self.verbose>2:\n",
    "                print(\"\")\n",
    "                print(\"KALMAN FILTER CALCULATION\")\n",
    "                print(\"\")\n",
    "                print(\"  Current Input\", lcl_current_input)\n",
    "            #Evolve the actual state\n",
    "            self.Dynamic_System.update(lcl_current_input)\n",
    "\n",
    "            #Calculate Kalman filter following https://en.wikipedia.org/wiki/Kalman_filter\n",
    "\n",
    "            \n",
    "            ##Predict\n",
    "            ###Compute Predicted X  (predicted a priori state estimte)\n",
    "            lcl_X_pred = self.Dynamic_System.dynamics(lcl_current_input, self.X)\n",
    "            if self.verbose>2:\n",
    "                print(\"\")\n",
    "                print (\"  Predicted X\", lcl_X_pred)\n",
    "            ####First step in covariance calculation based on dynamics and dynamics \"noise\"\n",
    "            if self.verbose>3:\n",
    "                print (\"Sigma\")\n",
    "                print (self.Sigma)\n",
    "\n",
    "            ###Compute Predicted P covariance\n",
    "            lcl_Sigma_Step_1 = lcl_A*self.Sigma*lcl_A.T+self.Q\n",
    "            if self.verbose>2:\n",
    "                print (\"  Predicted Covariance\", lcl_Sigma_Step_1)\n",
    "            \n",
    "\n",
    "            #Observe the system\n",
    "            lcl_Z = self.Dynamic_System.observe()\n",
    "            if self.verbose>3:\n",
    "                print (\"    Observed Value\")\n",
    "                print (lcl_Z)\n",
    "            \n",
    "            \n",
    "            ##Update\n",
    "\n",
    "            ###Calculate innovation pre-fit residual (error)\n",
    "            lcl_Y = lcl_Z - lcl_C * lcl_X_pred\n",
    "\n",
    "            ###Calculate innovation (or pre-fit redidual) covariance\n",
    "            #self.Sigma = (sym.Matrix.eye(2)-lcl_K*lcl_C)*lcl_Sigma_Step_1\n",
    "            self.Sigma = lcl_C * lcl_Sigma_Step_1 * lcl_C.T + self.R\n",
    "            if self.verbose>2:\n",
    "                print(\"  Innovation Covariance \", self.Sigma)\n",
    "            \n",
    "            #Compute the Kalman gain (used to weight observations and measurements)\n",
    "            #lcl_K = lcl_Sigma_Step_1 * lcl_C.T * (lcl_C*lcl_Sigma_Step_1*lcl_C.T + self.Q).inv()\n",
    "            lcl_K = lcl_Sigma_Step_1 * lcl_C.T * self.Sigma.inv()\n",
    "            if self.verbose>2:\n",
    "                print (\"  Updated Kalman Gain\", lcl_K)\n",
    "                \n",
    "            ###Updated (a posteriori) state estimate\n",
    "            lcl_X_filt = lcl_X_pred + lcl_K * (lcl_Y)\n",
    "            self.X = lcl_X_filt\n",
    "            \n",
    "            ###Updated (a posterriori) estimate of covariance\n",
    "            ###Get size of matrix\n",
    "            lcl_temp = lcl_K*lcl_C\n",
    "            ###Possible error, have to check if this must be square\n",
    "            lcl_size = lcl_temp.shape[1]\n",
    "            self.Sigma = (sym.Matrix.eye(lcl_size)-lcl_K*lcl_C)*lcl_Sigma_Step_1\n",
    "            if self.verbose>2:\n",
    "                print (\"  Updated (a posteriori) estimate of covariance\", self.Sigma)\n",
    "            \n",
    "            #Store relevant information in a vector\n",
    "            self.X_act_hist.append(self.Dynamic_System.state())\n",
    "            self.X_filt_hist.append(lcl_X_filt)\n",
    "            self.K_hist.append(lcl_K)\n",
    "            \n",
    "        if self.verbose>=1:\n",
    "            print(\"Final Values\")\n",
    "            print_matrix(\" X                          \", self.Dynamic_System.state())\n",
    "            print_matrix(\" Kalman Estimate of State X \", lcl_X_filt)\n",
    "            print_matrix(\" Final Covariance S(igma)   \", self.Sigma)\n",
    "            print_matrix(\" Final Kalman Gains K       \", lcl_K)\n",
    "    #def show(self):\n",
    "        #for idx in range(length(self.X_act_hist)):\n",
    "        #    print(\"State\")\n",
    "        #    print(self.X_act_hist.append[idx])\n",
    "        #    print(\"Kalman Estimate\")\n",
    "        #    print(self.X_filt_hist[idx])\n",
    "        #    print(\"Kalman Gain\")\n",
    "        #    print(self.K_hist[idx])\n",
    "\n",
    "def asymptotic_kal(lcl_A=[], lcl_B=[], lcl_R=[], lcl_C=[], lcl_Q=[], lcl_verbose=0):\n",
    "    lcl_An = np.matrix(lcl_A).astype(np.float64)\n",
    "    lcl_Bn = np.matrix(lcl_B).astype(np.float64)\n",
    "    lcl_Cn = np.matrix(lcl_C).astype(np.float64)\n",
    "    lcl_Qn = np.matrix(lcl_Q).astype(np.float64)\n",
    "    lcl_Rn = np.matrix(lcl_R).astype(np.float64)\n",
    "    \n",
    "    lcl_gP = linalg.solve_discrete_are(lcl_An, lcl_Cn, lcl_Qn, lcl_Rn)\n",
    "    #Change of notation\n",
    "    #gFn1 = gA1\n",
    "    #gGn1 = gB1\n",
    "    #gHn1 = gC1\n",
    "    #gRn1 = gR11\n",
    "    lcl_K = lcl_gP*lcl_Cn.T*((lcl_Cn*lcl_gP*lcl_Cn.T + lcl_Rn).I)\n",
    "    lcl_S = lcl_gP-lcl_K*lcl_Cn*lcl_gP\n",
    "    lcl_P = lcl_An*lcl_S*lcl_An.T + lcl_Bn*lcl_Qn*lcl_Bn.T\n",
    "    if lcl_verbose>0:\n",
    "        print(\"Asymptotic Evaluation of: \")\n",
    "        print_matrix(\" Covariance Matrix S(igma) \", lcl_S)\n",
    "        print_matrix(\" Kalman Gain K             \", lcl_K)\n",
    "    return(lcl_S, lcl_K, lcl_P)\n",
    "        \n",
    "#Define a utility function to setup up consistent dynamics and Kalman Filter\n",
    "def matched_system(lcl_A=[], lcl_B=[], lcl_X=[], lcl_R=[], lcl_C=[], lcl_Q=[],  lcl_Sigma=[], lcl_verbose=0):\n",
    "    #We note that the noise for our dynamic system is defined in terms for std not var\n",
    "    lcl_R2 = np.matrix(lcl_R).astype(np.float64)\n",
    "    #look into\n",
    "    #lcl_R2 = linalg.sqrtm(lcl_R2)\n",
    "    lcl_Q2 = np.matrix(lcl_Q).astype(np.float64)\n",
    "    #lcl_Q2 = linalg.sqrtm(lcl_Q2)\n",
    "    \n",
    "    lcl_dyn_sys = Dynamic_System(lcl_X, lcl_A, lcl_B, lcl_R2, lcl_C, lcl_Q2, lcl_verbose=lcl_verbose)\n",
    "    lcl_kal = Kalman_Filter(lcl_dyn_sys, lcl_Sigma, lcl_X, lcl_R, lcl_Q, lcl_verbose=lcl_verbose)\n",
    "    asymptotic_kal(lcl_A, lcl_B, lcl_R, lcl_C, lcl_Q,  lcl_verbose)\n",
    "    return(lcl_kal)\n",
    "\n",
    "\n",
    "def repeat_input(input, times):\n",
    "    input_list = [input]\n",
    "    for idx in range(times-1):\n",
    "        input_list.append(input)\n",
    "    return(input_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use this on our simple system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KALMAN FILTER CALCULATION\n",
      "\n",
      "  Current Input Matrix([[u]])\n",
      "\n",
      "  Predicted X Matrix([[u + xi]])\n",
      "  Predicted Covariance Matrix([[q**2 + si]])\n",
      "  Innovation Covariance  Matrix([[q**2 + r**2 + si]])\n",
      "  Updated Kalman Gain Matrix([[(q**2 + si)/(q**2 + r**2 + si)]])\n",
      "  Updated (a posteriori) estimate of covariance Matrix([[(q**2 + si)*(-(q**2 + si)/(q**2 + r**2 + si) + 1)]])\n",
      "Final Values\n",
      " X                           Matrix([[u + xi + (r**2)**0.5]])\n",
      " Kalman Estimate of State X  Matrix([[u + xi + (q**2 + si)*((q**2)**0.5 + (r**2)**0.5)/(q**2 + r**2 + si)]])\n",
      " Final Covariance S(igma)    Matrix([[(q**2 + si)*(-(q**2 + si)/(q**2 + r**2 + si) + 1)]])\n",
      " Final Kalman Gains K        Matrix([[(q**2 + si)/(q**2 + r**2 + si)]])\n"
     ]
    }
   ],
   "source": [
    "#Initial state\n",
    "g_verbose = 3\n",
    "gx_init =  sym.symbols('xi')\n",
    "gX_init  = sym.Matrix([[gx_init]])\n",
    "#Dynamics\n",
    "gA = sym.Matrix([[1]])\n",
    "#Inputs\n",
    "gB = sym.Matrix([[1]])\n",
    "#Mapping of states to measurements\n",
    "gC = sym.Matrix([[1]])\n",
    "#Noise on dynamics\n",
    "gr =  sym.symbols('r')\n",
    "gR = sym.Matrix([[gr**2]])\n",
    "#Noise on measurements\n",
    "gq =  sym.symbols('q')\n",
    "gQ = sym.Matrix([[gq**2]])\n",
    "gDyn_sys = Dynamic_System(gX_init, gA, gB, gR, gC, gQ, lcl_verbose=0)\n",
    "#Create a single input\n",
    "gu = sym.symbols('u')\n",
    "gsingle_input = repeat_input(sym.Matrix([[gu]]),1)\n",
    "#Initial covariance matrix\n",
    "gsigma_init = sym.symbols('si')\n",
    "gSigma_Init =  sym.Matrix([[gsigma_init]])\n",
    "#Call the raw calman filter\n",
    "gKal = Kalman_Filter(gDyn_sys, gSigma_Init, gX_init, gR, gQ, lcl_verbose=g_verbose)\n",
    "\n",
    "#gKal = matched_system(lcl_A=gA, lcl_B=gB, lcl_X=gX_init, lcl_R=gR, lcl_C=gC, lcl_Q=gQ, lcl_Sigma=gSigma_Init, lcl_verbose=1)\n",
    "gKal.update(gsingle_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No dynamic noise (dynamics are perfect) Kalman update becomes just the prediction in the limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default values for next set of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ginput_list = repeat_input(sym.Matrix([[1],  [1]]),100)\n",
    "gsingle_input = repeat_input(sym.Matrix([[1],  [1]]),1)\n",
    "gX_init  = sym.Matrix.zeros(2, 1)\n",
    "gSigma_Init =  sym.Matrix([[.1, 0], [0, .1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter Impact of Noise On Gains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next couple of sections we will explore what happens to the Kalman Filter with time\n",
    "\n",
    "As the Wiki points out you can express the X update in a more intuitive form\n",
    "\n",
    "$\\hat x = (I-KH)\\hat x_{k-1} + K(Hx + v)$\n",
    "\n",
    "Where we see a linear combination of the filtered state and the measured value\n",
    "\n",
    "https://en.wikipedia.org/wiki/Kalman_filter\n",
    "Equal Noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equal Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "[[0.01618034 0.        ]\n",
      " [0.         0.01618034]]\n",
      "[[0.02618034 0.        ]\n",
      " [0.         0.02618034]]\n",
      "<class 'numpy.matrix'>\n",
      "Asymptotic Covariance Matrix\n",
      "[[0.00618034 0.        ]\n",
      " [0.         0.00618034]]\n",
      "Asymptotic Kalman Gain K \n",
      "[[0.61803399 0.        ]\n",
      " [0.         0.61803399]]\n",
      "Asymptotic P\n",
      "[[0.01618034 0.        ]\n",
      " [0.         0.01618034]]\n",
      "Final Actual State X\n",
      "Matrix([[100.428639710877], [100.428639710877]])\n",
      "Kalman Estimate of State X\n",
      "Matrix([[100.404052022898], [100.404052022898]])\n",
      "Final Covariance S(igma)\n",
      "Matrix([[0.00618033988749895, 0], [0, 0.00618033988749895]])\n",
      "Final Kalman Gains K\n",
      "Matrix([[0.618033988749895, 0], [0, 0.618033988749895]])\n"
     ]
    }
   ],
   "source": [
    "#We expect this to result in equal gains and an approximately correct prediction\n",
    "#it is only approximately correct because the noise on the state and on the observation mean we cannot extract the exact values\n",
    "#R is the dynamic noise (error)\n",
    "\n",
    "#These are repeated to make this stand alone\n",
    "gX_init  = sym.Matrix.zeros(2, 1)\n",
    "gSigma_Init =  sym.Matrix([[.1, 0], [0, .1]])\n",
    "\n",
    "ginput_list = repeat_input(sym.Matrix([[1],  [1]]),100)\n",
    "\n",
    "#These are generally constant but also repeated to make the cell stand alone\n",
    "gA = sym.Matrix([[1, 0], [0, 1]])\n",
    "gB = sym.Matrix([[1, 0], [0, 1]])\n",
    "gC = sym.Matrix([[1, 0], [0, 1]])\n",
    "\n",
    "#These are problem to problem\n",
    "gQ = sym.Matrix([[0.01, 0], [0, 0.01]])\n",
    "gR = sym.Matrix([[0.01, 0], [0, 0.01]])\n",
    "\n",
    "#Q is observation noise\n",
    "gKal = matched_system(lcl_A=gA, lcl_B=gB, lcl_X=gX_init, lcl_R=gR, lcl_C=gC, lcl_Q=gQ, lcl_Sigma=gSigma_Init, lcl_verbose=1)\n",
    "gKal.update(ginput_list)\n",
    "#gKal.update(gsingle_input)\n",
    "#With initial definition of noise\n",
    "#0.00618\n",
    "#With sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No measurement noise (measurement is perfect) Kalman update becomes filtered prediction in the limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "Final Actual State \n",
      "Matrix([[99.9385165642261], [99.9385165642261]])\n",
      "Kalman Estimate of State\n",
      "Matrix([[99.9385165642261], [99.9385165642261]])\n",
      "Final Covariance\n",
      "Matrix([[0, 0], [0, 0]])\n",
      "Final Kalman Gains\n",
      "Matrix([[1.00000000000000, 0], [0, 1.00000000000000]])\n"
     ]
    }
   ],
   "source": [
    "#We expect this to result in a Kalman gain of about 1 where we are just taking the measurement\n",
    "#Since there is no noise we can extract the state exactly\n",
    "#Measurement noise zero\n",
    "gQ1 = gQ.subs('qx', gDef_Noise*0.00).subs('qy', gDef_Noise*0)\n",
    "#Dynamic noise default\n",
    "gR1 = gR.subs('rx', gDef_Noise).subs('ry', gDef_Noise)\n",
    "\n",
    "gKal = matched_system(lcl_A=gA, lcl_B=gB, lcl_X=gX_init, lcl_R=gR1, lcl_C=gC, lcl_Q=gQ1, lcl_Sigma=gSigma_Init, lcl_verbose=1)\n",
    "gKal.update(ginput_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "Final Actual State \n",
      "Matrix([[99.9385165642261], [100]])\n",
      "Kalman Estimate of State\n",
      "Matrix([[99.9385165642261], [99.9996330418354]])\n",
      "Final Covariance\n",
      "Matrix([[0, 0], [0, 9.99000999000999e-5]])\n",
      "Final Kalman Gains\n",
      "Matrix([[1.00000000000000, 0], [0, 0.00999000999000999]])\n"
     ]
    }
   ],
   "source": [
    "#Here we make the first state perfectly observable and the second not\n",
    "#The dyamic error on the first state is not zero, but on the second state it is\n",
    "#Here we see the expected first state with very high Kalman gain and the second with very low\n",
    "gQ1 = gQ.subs('qx', gDef_Noise*0.00).subs('qy', gDef_Noise)\n",
    "#Dynamic noise default\n",
    "gR1 = gR.subs('rx', gDef_Noise).subs('ry', gDef_Noise*0)\n",
    "\n",
    "gKal = matched_system(lcl_A=gA, lcl_B=gB, lcl_X=gX_init, lcl_R=gR1, lcl_C=gC, lcl_Q=gQ1, lcl_Sigma=gSigma_Init, lcl_verbose=1)\n",
    "gKal.update(ginput_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is of course a mathematical issue if all the noise is zero.  The Kalman gain is the inverse of $C*S*C^T+Q$ clearly if the Kalman gain is singular the first term can become singular.  However, only if the assumed measurement noise is singular will the whole expression be guaranteed to be singular.  If the measurement noise is zero you DON'T need a Kalman filter.  The obvious answer is the state is the measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "Final Actual State \n",
      "Matrix([[1], [1]])\n",
      "Kalman Estimate of State\n",
      "Matrix([[1], [1]])\n",
      "Final Covariance\n",
      "Matrix([[0, 0], [0, 0]])\n",
      "Final Kalman Gains\n",
      "Matrix([[1.00000000000000, 0], [0, 1.00000000000000]])\n"
     ]
    }
   ],
   "source": [
    "gQ1 = gQ.subs('qx', gDef_Noise*0.00).subs('qy', gDef_Noise*0.0)\n",
    "#Dynamic noise default\n",
    "gR1 = gR.subs('rx', gDef_Noise*0.0).subs('ry', gDef_Noise*0)\n",
    "\n",
    "gKal = matched_system(lcl_A=gA, lcl_B=gB, lcl_X=gX_init, lcl_R=gR1, lcl_C=gC, lcl_Q=gQ1, lcl_Sigma=gSigma_Init, lcl_verbose=1)\n",
    "gKal.update(gsingle_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other thing to look at is what the covariance converges to.  Given noise of 0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "Final Actual State \n",
      "Matrix([[99.9385165642261], [99.9385165642261]])\n",
      "Kalman Estimate of State\n",
      "Matrix([[99.9509629226324], [99.9509629226324]])\n",
      "Final Covariance\n",
      "Matrix([[0.00618033988749895, 0], [0, 0.00618033988749895]])\n",
      "Final Kalman Gains\n",
      "Matrix([[0.618033988749895, 0], [0, 0.618033988749895]])\n"
     ]
    }
   ],
   "source": [
    "gR1 = gR.subs('rx', gDef_Noise).subs('ry', gDef_Noise)\n",
    "#Q is observation noise\n",
    "gQ1 = gQ.subs('qx', gDef_Noise).subs('qy', gDef_Noise)\n",
    "gKal = matched_system(lcl_A=gA, lcl_B=gB, lcl_X=gX_init, lcl_R=gR1, lcl_C=gC, lcl_Q=gQ1, lcl_Sigma=gSigma_Init, lcl_verbose=1)\n",
    "gKal.update(ginput_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "Final Actual State \n",
      "Matrix([[1.09417154046807], [1.09417154046807]])\n",
      "Kalman Estimate of State\n",
      "Matrix([[0.970914126950111], [0.970914126950111]])\n",
      "Final Covariance\n",
      "Matrix([[0.0666666666666667, 0], [0, 0.0666666666666667]])\n",
      "Final Kalman Gains\n",
      "Matrix([[0.666666666666667, 0], [0, 0.666666666666667]])\n"
     ]
    }
   ],
   "source": [
    "gQ1 = gQ.subs('qx', gDef_Noise*10).subs('qy', gDef_Noise*10)\n",
    "#Dynamic noise default\n",
    "gR1 = gR.subs('rx', gDef_Noise*10).subs('ry', gDef_Noise*10)\n",
    "gKal = matched_system(lcl_A=gA, lcl_B=gB, lcl_X=gX_init, lcl_R=gR1, lcl_C=gC, lcl_Q=gQ1, lcl_Sigma=gSigma_Init, lcl_verbose=1)\n",
    "gKal.update(gsingle_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about steady state convergence (note this is another common notation where W=R and V=Q, note we don't need the B matrix here\n",
    "\n",
    "$\\Sigma_{t+1} =A\\Sigma A^T + W - A\\Sigma C^T(C\\Sigma C^T+V)^{-1}C\\Sigma A^T$\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.solve_discrete_are.html\n",
    "\n",
    "$A\\Sigma A^T - \\Sigma + W - A\\Sigma C^T(C\\Sigma C^T+V)^{-1}C\\Sigma A^T$\n",
    "\n",
    "or from\n",
    "\n",
    "$A^HXA - X - A^HXB(R+B^HXB)^{-1}(B^HXA)+ Q$\n",
    "\n",
    "Clearly X=Sigma A=A B=C R=R and Q=Q\n",
    "\n",
    "https://laurentlessard.com/teaching/me7247/lectures/lecture%2012%20-%20steady-state%20Kalman%20filter.pdf\n",
    "\n",
    "From SciPy\n",
    "\n",
    "\n",
    "https://ocw.mit.edu/courses/2-160-identification-estimation-and-learning-spring-2006/825d8851ab6950cebfab991c3e435f90_lecture_7.pdf\n",
    "\n",
    "scipy.linalg.solve_discrete_are(a, b, q, r)[source]¶\n",
    "\n",
    "\n",
    "So it seems like we should be able to predetermine the value of the Kalman filter, that should also be a check on our implementation see https://stanford.edu/class/ee363/lectures/kf.pdf\n",
    "\n",
    "Indeed this is the case \n",
    "\n",
    "$\\Sigma_x=A \\Sigma_x A^T + B \\Sigma_u B^T$\n",
    "\n",
    "Scipi provides the solution to continious lyapunov equation\n",
    "\n",
    "$AX + XA^H = Q$\n",
    "\n",
    "Scipi provides the solution to and the discrete \n",
    "\n",
    "$AXA^H -X + Q = 0$\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.solve_discrete_lyapunov.html#scipy.linalg.solve_discrete_lyapunov\n",
    "\n",
    "\n",
    "\n",
    "To make these equivalent we use\n",
    "$-A^{-1} \\Sigma_x + \\Sigma_x A^T = -A^{-1}*B*\\Sigma_u*B^T$\n",
    "\n",
    "Convieniently with our A and B both identities\n",
    "$\\Sigma_x + \\Sigma_x = \\Sigma_u$\n",
    "\n",
    "\n",
    "https://spinlab.wpi.edu/courses/ece531_2013/7-5ss_kf_performance.pdf\n",
    "\n",
    "https://spinlab.wpi.edu/courses/ece531_2013/7-5ss_kf_performance.pdf\n",
    "\n",
    "\n",
    "$K = PH^T(HPH^T + R)^{-1}$\n",
    "\n",
    "$S = P - KHP$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0.01 0.  ]\n",
      " [0.   0.01]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[0.01 0.  ]\n",
      " [0.   0.01]]\n",
      "[[0.01 0.  ]\n",
      " [0.   0.01]]\n",
      "d1\n",
      "[[0.01618034 0.        ]\n",
      " [0.         0.01618034]]\n",
      "<class 'numpy.matrix'>\n",
      "d2\n",
      "[[0.02618034 0.        ]\n",
      " [0.         0.02618034]]\n",
      "K\n",
      "[[0.61803399 0.        ]\n",
      " [0.         0.61803399]]\n",
      "S\n",
      "[[0.00618034 0.        ]\n",
      " [0.         0.00618034]]\n",
      "P\n",
      "[[0.01618034 0.        ]\n",
      " [0.         0.01618034]]\n"
     ]
    }
   ],
   "source": [
    "gQ11 = np.matrix(gQ.subs('qx', gDef_Noise).subs('qy', gDef_Noise)).astype(np.float64)\n",
    "gR11 = np.matrix(gR.subs('rx', gDef_Noise).subs('ry', gDef_Noise)).astype(np.float64)\n",
    "gA1 = np.matrix(gA).astype(np.float64)\n",
    "gB1 = np.matrix(gB).astype(np.float64)\n",
    "gC1 = np.matrix(gC).astype(np.float64)\n",
    "print(gA1)\n",
    "print(gQ11)\n",
    "#gCL=linalg.solve_continuous_lyapunov(gA1, gQ11)\n",
    "#gDL=linalg.solve_discrete_lyapunov(gA1, gQ11, 'bilinear')\n",
    "print(gA1)\n",
    "print(gC1)\n",
    "print(gQ11)\n",
    "print(gR11)\n",
    "gP = linalg.solve_discrete_are(gA1, gC1, gQ11, gR11)\n",
    "#Change of notation\n",
    "gFn1 = gA1\n",
    "gGn1 = gB1\n",
    "gHn1 = gC1\n",
    "gRn1 = gR11\n",
    "gQn1 = gQ11\n",
    "gK = gP*gHn1.T*((gHn1*gP*gHn1.T + gRn1).I)\n",
    "print(\"d1\")\n",
    "print(gP*gHn1.T)\n",
    "print(type(gP*gHn1.T))\n",
    "print(\"d2\")\n",
    "print(gHn1*gP*gHn1.T + gRn1)\n",
    "gS = gP-gK*gHn1*gP\n",
    "gP = gFn1*gS*gFn1.T + gGn1*gQn1*gGn1.T\n",
    "\n",
    "print(\"K\")\n",
    "print(gK)\n",
    "print(\"S\")\n",
    "print(gS)\n",
    "print(\"P\")\n",
    "print(gP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "Final Actual State \n",
      "Matrix([[99.9385165642261], [99.9385165642261]])\n",
      "Kalman Estimate of State\n",
      "Matrix([[99.9509629226324], [99.9509629226324]])\n",
      "Final Covariance\n",
      "Matrix([[0.00618033988749895, 0], [0, 0.00618033988749895]])\n",
      "Final Kalman Gains\n",
      "Matrix([[0.618033988749895, 0], [0, 0.618033988749895]])\n"
     ]
    }
   ],
   "source": [
    "gSigma_Init =  sym.Matrix([[0.005, 0], [0, 0.005]])\n",
    "gQ1 = gQ.subs('qx', gDef_Noise).subs('qy', gDef_Noise)\n",
    "#Dynamic noise default\n",
    "gR1 = gR.subs('rx', gDef_Noise).subs('ry', gDef_Noise)\n",
    "gKal = matched_system(lcl_A=gA, lcl_B=gB, lcl_X=gX_init, lcl_R=gR1, lcl_C=gC, lcl_Q=gQ1, lcl_Sigma=gSigma_Init, lcl_verbose=1)\n",
    "gKal.update(ginput_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come back to this it mentions adjoint method so interesting to see what adjoint means here\n",
    "https://byjus.com/maths/symmetric-matrix/#:~:text=Some%20of%20the%20symmetric%20matrix%20properties%20are%20given,inverse%20of%20a%20transpose%20matrix.%20More%20items...%20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
